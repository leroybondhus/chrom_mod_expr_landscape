---
title: "expr_data_setup"
author: "Leroy Bondhus"
date: "2023-08-20"
output: html_document
---

### NOTE: Previous issue for accessing gtex data due to url change - info on correct format for url access to resource on google cloud found at https://cloud.google.com/storage/docs/access-public-data#api-link 

```{r, load libraries}
# req_packages <- list(
#   standard = c("dendextend","factoextra","cowplot"),
#   biocmanager = c("Gviz","biomaRt")
# )
# for(std_package in req_packages$standard ){
#   if(!require(std_package, quietly=T, character.only=T)){install.packages(std_package)}
# };rm(std_package)
# for(bioc_package in req_packages$biocmanager ){
#   if(!require(bioc_package, quietly=T, character.only=T)){BiocManager::install(bioc_package)}
# };rm(bioc_package)
# rm(req_packages)

```


```{r}
if(!exists("dataset_list")){dataset_list <- list()}
registerDoParallel(detectCores()-2)
files$temp_log <- paste0(dirs$temp_data,"temp.log")
# library(jsonlite)
# library(httr)
# library(dendextend)
# library(factoextra)
# library(cowplot)
```

```{r}
### look into this as supplement/alt to encode
## https://stemangiola.github.io/CuratedAtlasQueryR/
```


```{r, encode human RNA}

print(Sys.time())
# search_query <- "https://www.encodeproject.org/search/?type=Experiment&related_series.@type=ReferenceEpigenome&status=released&replicates.library.biosample.donor.organism.scientific_name=Mus+musculus&assay_title=polyA+plus+RNA-seq&frame=object&format=json&limit=all"
# 
search_query <- paste0("https://www.encodeproject.org/search/",
                       "?type=Experiment&control_type!=*&status=released&perturbed=false",
                       "&assay_title=total+RNA-seq&assay_title=polyA+plus+RNA-seq", #
                       "&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens",
                       "&format=json&limit=all")
#"https://www.encodeproject.org/search/?type=Experiment&related_series.@type=ReferenceEpigenome&status=released&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&assay_title=polyA+plus+RNA-seq&frame=object&format=json&limit=all"
query_result <- GET(search_query)
query_result <- httr::content(query_result , "text", encoding = "UTF-8")
query_result <- fromJSON(query_result, flatten = T)
query_table <- query_result$`@graph`[!unlist(lapply(query_result$`@graph`, is.list))]

##
#data_list <- list()
#foreach(simul_pars = simul_pars_list, .final = function(x) setNames(x, names(simul_pars_list)), .errorhandling = "pass") %dopar% {
system(paste0("echo \"\" > ",files$temp_log))
data_list <- foreach(i=1:nrow(query_table) , .errorhandling = "pass") %dopar% { #nrow(query_table)
#for(i in 1:nrow(query_table)){
  #if(i %% 5 == 0){print(i)}
  system(paste0("echo \"processing: ",i, "\" >> ",files$temp_log))
  target <- paste0("https://www.encodeproject.org/",
                          query_table$accession[i],
                          "/?frame=embedded&format=json")
  target <- GET(target)
  target_result <- httr::content(target, "text", encoding = "UTF-8")
  target_result <- fromJSON(target_result, flatten = TRUE)
  temp_gene_anno <-  unique(target_result$files$genome_annotation)
  temp_gene_anno <- temp_gene_anno[grep("ENSEMBL", temp_gene_anno,invert = T)]
  which <- which(target_result$files$file_format=="tsv" &
                 target_result$files$output_type=="gene quantifications" &
                 grepl(max(as.numeric(str_remove_all(temp_gene_anno,"[a-zA-Z]")),na.rm = T),
                       target_result$files$genome_annotation) &
                 target_result$files$status == "released")
  if(length(which)==0){next}
  
  
  
  which_cols <- c("accession", "href","biosample_ontology",
                "biological_replicates", "technical_replicates",
                "biological_replicates_formatted", "donors",
                "dataset")
  gene_quant_files <- target_result$files[which,which_cols]
  gene_quant_files[,which(unlist(lapply(gene_quant_files, is.list)))] <- 
    sapply(gene_quant_files[,which(unlist(lapply(gene_quant_files, is.list)))], paste )
  target_coldata <- cbind(query_table[i,], gene_quant_files)
  target_coldata$life_stage_age <- ifelse(is.null(target_result$life_stage_age),NA,target_result$life_stage_age)
  
  if(all(is.na(target_coldata$life_stage_age))){
    temp_pattern = paste0("[0-9-]+ day|day [0-9-]+|[0-9-]+ week|[0-9-]+ month|[0-9-]+ year",
                           "|embryo|fetus|neonat|newborn|child|teen|adult")
    target_coldata$life_stage_age <- paste0(unlist(str_extract_all(tolower(query_table$biosample_summary[i]),temp_pattern)),collapse = ",")
  }
  
  
  for(j in 1:nrow(target_coldata)){
    temp <- tempfile()
    download.file(paste0("https://www.encodeproject.org/",target_coldata$href[j]), temp)
    temp_data <- read.table(temp, skip = 0, header = TRUE, sep = "\t")
    temp_data <- temp_data[grep("PAR_Y",temp_data$gene_id, invert=T),]
    temp_list <- list(TPM = data.frame(TPM=temp_data$TPM),
                      coldata = cbind(target_coldata[j,], read_count=sum(temp_data$posterior_mean_count) ) )
    rownames(temp_list$TPM) <- str_remove(temp_data$gene_id,"\\..*")
  }
  temp_list
}

data_list_backup <- data_list
data_list <- data_list[which(sapply(data_list, function(x){!all(names(x)==c("message","call"))}))]

temp_data_list_qc <- data.frame(tpm_nrow=numeric(length=length(data_list)),
                                tpm_ncol=numeric(length=length(data_list)),
                                coldata_nrow=numeric(length=length(data_list)))
temp_rownames <- character()
for(i in 1:length(data_list)){
  temp_data_list_qc$tpm_nrow[i] <- nrow(data_list[[i]]$TPM)
  temp_data_list_qc$tpm_ncol[i] <- ncol(data_list[[i]]$TPM)
  temp_data_list_qc$coldata_nrow[i] <- nrow(data_list[[i]]$coldata)
  temp_rownames <- unique(c(temp_rownames,rownames(data_list[[i]]$TPM)))
}
for(i in 1:length(data_list)){
  temp_missing_rownames <- setdiff(temp_rownames, rownames(data_list[[i]]$TPM))
  if(length(temp_missing_rownames)==0){next}
  temp_df <- data.frame(TPM = rep(0, length(temp_missing_rownames)))
  rownames(temp_df) <- temp_missing_rownames
  data_list[[i]]$TPM <- rbind(data_list[[i]]$TPM, temp_df)
}
for(i in 1:length(data_list)){
  temp_data_list_qc$tpm_nrow[i] <- nrow(data_list[[i]]$TPM)
  temp_data_list_qc$tpm_ncol[i] <- ncol(data_list[[i]]$TPM)
  temp_data_list_qc$coldata_nrow[i] <- nrow(data_list[[i]]$coldata)
}
#### fix dim mismatch issue for human data here ..... 
if( nrow(unique(temp_data_list_qc)) != 1){stop("dimension mismatch between objects")}

data_list_concat <- data_list[[1]]
for(i in 2:length(data_list)){
  data_list_concat$TPM <- cbind(data_list_concat$TPM, data_list[[i]]$TPM)
  data_list_concat$coldata <- rbind(data_list_concat$coldata, data_list[[i]]$coldata)
}
data_list_concat$coldata <- as.data.frame(data_list_concat$coldata)

dataset_list$ENCODE_HH <- list(mat = data_list_concat$TPM, coldata=data_list_concat$coldata)
which <- grep("_UBERON_|_CL_", dataset_list$ENCODE_HH$coldata$biosample_ontology)
dataset_list$ENCODE_HH$mat <- dataset_list$ENCODE_HH$mat[,which]
dataset_list$ENCODE_HH$coldata <- dataset_list$ENCODE_HH$coldata[which,]

rm(data_list, query_result, query_table, temp_data, temp_df,
   data_list_concat, temp_missing_rownames, search_query, temp_rownames)


temp <- tempfile()
temp_url <- "https://storage.googleapis.com/adult-gtex/bulk-gex/v8/rna-seq/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz"
temp <- tempfile()
download.file(temp_url,temp)

dataset_list$GTEX <- list()
dataset_list$GTEX$median_mat <- read.table( temp, skip=2, header = TRUE, sep = "\t")
dataset_list$GTEX$median_mat_rowinfo <-  data.frame(Name=dataset_list$GTEX$median_mat$Name,
                                                    Description=dataset_list$GTEX$median_mat$Description)
rownames(dataset_list$GTEX$median_mat) <- dataset_list$GTEX$median_mat_rowinfo$Name
dataset_list$GTEX$median_mat <- as.matrix(dataset_list$GTEX$median_mat[,3:ncol(dataset_list$GTEX$median_mat)])
unlink(temp); rm(temp)


temp <- tempfile() 
temp_url <- "https://storage.googleapis.com/adult-gtex/annotations/v8/metadata-files/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt"
download.file(temp_url,temp)
temp <- read.csv( temp, skip=0, header = TRUE, sep = "\t")
temp <- unique(data.frame(colname=temp$SMTSD,uberon_id=temp$SMUBRID))
temp$sim_colname <- tolower(str_remove_all(temp$colname, "[ \\.\\-\\(\\)]"))  
dataset_list$GTEX$median_mat_colinfo <- temp[match(tolower(str_remove_all(colnames(dataset_list$GTEX$median_mat),
                                                                          "[ \\.\\-(\\)]")),
                                                   temp$sim_colname,),]
dataset_list$GTEX$median_mat_colinfo$colname <- colnames(dataset_list$GTEX$median_mat) 
which_keep <- grep("EFO_",dataset_list$GTEX$median_mat_colinfo$uberon_id,invert = T)
dataset_list$GTEX$median_mat_colinfo <- dataset_list$GTEX$median_mat_colinfo[which_keep,] 
dataset_list$GTEX$median_mat <- dataset_list$GTEX$median_mat[,which_keep]
which <- grep("UBERON:",dataset_list$GTEX$median_mat_colinfo$uberon_id,invert = T)
dataset_list$GTEX$median_mat_colinfo$uberon_id[which] <- paste0("UBERON:",dataset_list$GTEX$median_mat_colinfo$uberon_id[which])

### merge common biosample types (e.g. get median expression for all)
print(Sys.time())
save.image("./post_full_mat.Rdata") ## next aggregate common samples into median expr values
```


```{r}
ensembl <- useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl")
genes <- getBM(attributes=c('chromosome_name','start_position','end_position','hgnc_symbol', 'ensembl_gene_id','gene_biotype'),
                 filters = list('biotype'=c('protein_coding','lincRNA')),
                 mart = ensembl, useCache = F) 
genes <- genes[which(is.element(genes$chromosome_name, c(1:22, "X", "Y", "MT")) & genes$ensembl_gene_id != "" ) ,]
gene_sets$for_hh_expr <- genes
rm(genes)
```

```{r}
# mat <- dataset_list$ENCODE_HH$mat[,ehh]
# coldata <- dataset_list$ENCODE_HH$coldata[ehh,]
# colnames(mat) <- make.unique(coldata$accession)

### select rows (e.g. remove mitochondria)
which <- which(gene_sets$for_hh_expr$chromosome_name != "MT" )
mat <- dataset_list$ENCODE_HH$mat
coldata <- dataset_list$ENCODE_HH$coldata
colnames(mat) <- make.unique(coldata$accession)

mat_cleaned <- mat[which(is.element(rownames(mat),
                                    gene_sets$for_hh_expr$ensembl_gene_id[which])),]
### normalize : re-calculate TPM, log10+1 transform, median normalize
for(i in 1:ncol(mat_cleaned)){
  mat_cleaned[,i] <- (mat_cleaned[,i]*1e6 / sum(mat_cleaned[,i]))
  ## set all very low counts to zero to avoid variable read depth issues
  mat_cleaned[,i] [which(mat_cleaned[,i]  < 1)] <- 0
  mat_cleaned[,i] <- (mat_cleaned[,i]*1e6 / sum(mat_cleaned[,i]))
}
mat_cleaned <- log10(mat_cleaned+1)
median_normalize <- TRUE
if(median_normalize){
  for(i in 1:ncol(mat_cleaned)){
    mat_cleaned[,i] <- mat_cleaned[,i] / median(mat_cleaned[,i][which(mat_cleaned[,i] > log10(1+1))])
  }
}
colnames(mat_cleaned) <- make.unique(
  dataset_list$ENCODE_HH$coldata$biosample_ontology.term_name)

dataset_list$ENCODE_HH$median_norm_mat <- mat_cleaned
```



```{r, preprocesss datasets}
## seperate out different assay types.... probs should do this earlier..

### aggregate on common 

convert_str_to_rel_age <- function(in_str){
  base_age_min <- base_age_max <- 0
  is_neonat <- grepl("neonat|newborn",tolower(in_str))
  is_embryo <- grepl("embryo",tolower(in_str))
  if(!is_embryo){
    base_age_min <- 30*9
    base_age_max <- 30*9
  }
  num_values <- as.numeric(unlist(str_extract_all(in_str, "[0-9]+")))
  quant_values <- unlist(str_extract_all(tolower(in_str), "day|week|month|year"))
  if(length(quant_values)==1){quant_values <- rep(quant_values, length(num_values))}
  
  quant_values[which(quant_values=="day")] <- 1
  quant_values[which(quant_values=="week")] <- 7
  quant_values[which(quant_values=="month")] <- 30
  quant_values[which(quant_values=="year")] <- 365
  quant_values <- as.numeric(quant_values)
  if(length(quant_values) != length(num_values) | length(num_values)==0){
    quant_values<-1; num_values<-0
    if(is_embryo){
      base_age_max=30*9-1
    }else if(!is_neonat){
      return(data.frame(min_age_est=NA,
                        mean_age_est=NA,
                        max_age_est=NA))
    }
  }
  max_age_est <- max(quant_values*num_values+base_age_max)
  if(is_neonat &  max_age_est < 30*9){
    max_age_est <- 30*9
  }
  return(data.frame(min_age_est=min(quant_values*num_values+base_age_min),
              mean_age_est=mean(quant_values*num_values+(base_age_min+base_age_max)/2 ),
              max_age_est=max_age_est ))
}

convert_range_to_ordered_factor <- function(in_str){
  df <- unique(str_split_fixed(in_str,"-",2))
  df <- df[order(as.numeric(df[,1]),as.numeric(df[,2])),]
  out_fctr <- paste(df[,1],df[,2],sep="-")
  out_fctr <- str_replace(out_fctr, "-$|^-","")
  return(factor(in_str, levels=out_fctr))
}

coldata <- dataset_list$ENCODE_HH$coldata
mat <- dataset_list$ENCODE_HH$median_norm_mat

temp_time_ests <- NULL
for(i in 1:length(coldata$life_stage_age)){
   temp_time_ests <- rbind(temp_time_ests,
                           convert_str_to_rel_age(coldata$life_stage_age[i]))
}
coldata$min_age_est <- temp_time_ests$min_age_est
coldata$max_age_est <- temp_time_ests$max_age_est


coldata <- coldata[,c("assay_term_name","biosample_ontology","biosample_ontology.term_name","min_age_est","max_age_est")]

age_group_cuts <- c(0,2^c(0:16))

coldata$age_group <- -1
for(i in 1:nrow(coldata)){
  min_val <- coldata$min_age_est[i]
  which_min <- which( min_val < age_group_cuts[2:length(age_group_cuts)] & 
                        min_val >= age_group_cuts[1:(length(age_group_cuts)-1)])
  max_val <- coldata$max_age_est[i]
  which_max <- which( max_val < age_group_cuts[2:length(age_group_cuts)] & 
                        max_val >= age_group_cuts[1:(length(age_group_cuts)-1)])+1
  coldata$age_group[i] <- paste0(c(age_group_cuts[which_min],age_group_cuts[which_max]),collapse = "-")
}


coldata$age_group <- convert_range_to_ordered_factor(coldata$age_group)

coldata$min_age_est <- NULL
coldata$max_age_est <- NULL
coldata$onto_w_age <-
  paste0(coldata$biosample_ontology, coldata$age_group, coldata$assay_term_name)

temp_coldata <- unique(coldata)
temp_mat <- matrix(nrow = nrow(mat),ncol=nrow(temp_coldata),dimnames = list(rownames(mat),NULL)) 
for(i in 1:nrow(temp_coldata)){
  which_col <- which(coldata$onto_w_age == temp_coldata$onto_w_age[i])
  temp_mat[,i] <- rowMeans(mat[,which_col,drop=F])
}


dataset_list$ENCODE_HH$agg_med_norm__mat <- temp_mat
dataset_list$ENCODE_HH$agg_med_norm__coldata <- temp_coldata
```

```{r, get merge gtex encode dataset}
temp_mat <- dataset_list$ENCODE_HH$agg_med_norm__mat
temp_coldata <- dataset_list$ENCODE_HH$agg_med_norm__coldata

temp_gtex_coldata <- dataset_list$GTEX$median_mat_colinfo
temp_encode_coldata <- dataset_list$ENCODE_HH$agg_med_norm__coldata

temp_gtex_mat <- dataset_list$GTEX$median_mat
temp_encode_mat <- dataset_list$ENCODE_HH$agg_med_norm__mat 

rownames(temp_gtex_mat) <- str_remove(rownames(temp_gtex_mat), "\\.[0-9]+")
temp_rownames <- intersect(rownames(temp_encode_mat),rownames(temp_gtex_mat))

temp_gtex_mat <- temp_gtex_mat[match(temp_rownames,rownames(temp_gtex_mat)),]
temp_encode_mat <- temp_encode_mat[match(temp_rownames,rownames(temp_encode_mat)),]

temp_gtex_coldata$onto_id <- temp_gtex_coldata$uberon_id
temp_encode_coldata$onto_id <- str_extract(temp_encode_coldata$biosample_ontology,
                                           "_CL_.*|_UBERON_.*")
temp_encode_coldata$onto_id <- str_extract(temp_encode_coldata$onto_id,
                                           "CL_[0-9]+|UBERON_[0-9]+")
temp_encode_coldata$onto_id <- str_replace(temp_encode_coldata$onto_id,"_",":")

temp_gtex_coldata$age_group <- ""
temp_gtex_coldata$assay <- "polyA plus RNA-seq"

temp_encode_coldata$colname <- paste0(temp_encode_coldata$biosample_ontology.term_name, "..",
                                      temp_encode_coldata$age_group,"..",
                                      temp_encode_coldata$assay)
temp_encode_coldata$assay <- temp_encode_coldata$assay_term_name
colnames(temp_encode_mat) <- temp_encode_coldata$colname

temp_encode_coldata <- temp_encode_coldata[,c("colname","onto_id","age_group","assay")]
temp_gtex_coldata <- temp_gtex_coldata[,c("colname","onto_id","age_group","assay")]

temp_coldata <- rbind(temp_gtex_coldata, temp_encode_coldata)

## perform same set of normalization on gtex as on encode before binding

### normalize : re-calculate TPM, log10+1 transform, median normalize
for(i in 1:ncol(temp_gtex_mat)){
  temp_gtex_mat[,i] <- (temp_gtex_mat[,i]*1e6 / sum(temp_gtex_mat[,i]))
  ## set all very low counts to zero to avoid variable read depth issues
  temp_gtex_mat[,i] [which(temp_gtex_mat[,i]  < 1)] <- 0
  temp_gtex_mat[,i] <- (temp_gtex_mat[,i]*1e6 / sum(temp_gtex_mat[,i]))
}
temp_gtex_mat <- log10(temp_gtex_mat+1)
median_normalize <- TRUE
if(median_normalize){
  for(i in 1:ncol(temp_gtex_mat)){
    temp_gtex_mat[,i] <- temp_gtex_mat[,i] / median(temp_gtex_mat[,i][which(temp_gtex_mat[,i] > log10(1+1))])
  }
}  

temp_mat <- cbind(temp_gtex_mat,temp_encode_mat)
colnames(temp_mat) <- c(colnames(temp_gtex_mat),colnames(temp_encode_mat))
all(colnames(temp_mat)==temp_coldata$colname)
dataset_list$ENCODE_GTEX_COMB <- list(mat=temp_mat,
                                      coldata=temp_coldata)
which_rm <- grep("mole|layer of hippocamp",dataset_list$ENCODE_GTEX_COMB$coldata$colname)
dataset_list$ENCODE_GTEX_COMB$coldata <- dataset_list$ENCODE_GTEX_COMB$coldata[-which_rm,]  
dataset_list$ENCODE_GTEX_COMB$mat <- dataset_list$ENCODE_GTEX_COMB$mat[,-which_rm]
```


```{r, embed in ontology}

### add cardiac ventricles and cardiac atria as proxy for cardiac muscle tissue
temp_id <- ontos$uberon$ont$id[which(ontos$uberon$ont$name=="cardiac muscle tissue")]
which <- which(ontos$uberon$ont$name == "cardiac atrium")
ontos$uberon$ont$relations[[which]] <- unique(rbind(ontos$uberon$ont$relations[[which]],
                                                    data.frame(relation="proxy_for(SUPP)",id=temp_id)))
which <- which(ontos$uberon$ont$name == "cardiac ventricle")
ontos$uberon$ont$relations[[which]] <- unique(rbind(ontos$uberon$ont$relations[[which]],
                                                    data.frame(relation="proxy_for(SUPP)",id=temp_id)))
temp_id <- ontos$uberon$ont$id[which(ontos$uberon$ont$name=="skeletal muscle tissue")]
which <- which(ontos$uberon$ont$name == "skeletal muscle organ")
ontos$uberon$ont$relations[[which]] <- unique(rbind(ontos$uberon$ont$relations[[which]],
                                                    data.frame(relation="proxy_for(SUPP)",id=temp_id)))

#onto <- ontos$uberon$ont

### is_a, part_of, develops_from ...

#### development lineage building pseudocode
### if x develops_from y , x --> y, else if x is_a y, go_tzo y, repeat. ##  
### 
### annotate ontology with is_a and part_of
ontos$uberon$ont <- add_inverse_relation(ontos$uberon$ont, "develops_from","devolops_into(SUPP_INV(develops_from))")


# temp_uberon_ids <- str_extract(dataset_list$ENCODE_HH$agg_med_norm__coldata$biosample_ontology,"UBERON.[0-9]*")
# temp_uberon_ids <- str_replace(temp_uberon_ids,"_",":")
temp_uberon_ids <- str_extract(dataset_list$ENCODE_GTEX_COMB$coldata$onto_id,"UBERON:[0-9]*")



ontos$uberon$ont$ehh <- vector("list", length(ontos$uberon$ont$id))
for(i in 1:length(temp_uberon_ids)){
  if(i %% 100 == 0){print(i)}
  if(is.na(temp_uberon_ids[i])){next}
  ontos$uberon$ont <- add_annotation(temp_uberon_ids[i], ontos$uberon$ont, "ehh", i,
                         transitive_relations = c("part_of",  "is_a", "proxy_for(SUPP)" ))  
}


# temp_cl_ids <- str_extract(dataset_list$ENCODE_HH$agg_med_norm__coldata$biosample_ontology,"CL.[0-9]*")
# temp_cl_ids <- str_replace(temp_cl_ids,"_",":")
temp_cl_ids <- str_extract(dataset_list$ENCODE_GTEX_COMB$coldata$onto_id,"CL:[0-9]*")

ontos$cl$ont$ehh <- vector("list", length(ontos$cl$ont$id))
for(i in 1:length(temp_cl_ids)){
  if(i %% 100 == 0){print(i)}
  if(is.na(temp_cl_ids[i])){next}
  ontos$cl$ont <- add_annotation(temp_cl_ids[i], ontos$cl$ont, "ehh", i,
                         transitive_relations = c("part_of",  "is_a", "proxy_for(SUPP)" ))  
}



### map cells to uberon concept if "CL is part_of UBERON"
## modified to include depth of ancestor
get_onto_paired_concepts <- function(id, onto, inter_onto_relations=c("is_a","part_of")){
  which <- which(onto$id == id)
  temp_anc <- get_ancestors(id,onto)
  temp_ext_rels <- c()
  for(i in 1:length(temp_anc)){
    temp_which_anc <- which(onto$id == temp_anc[i])
    if(is.null(onto$external_relations[[temp_which_anc]])){next}
    temp_ext_rels <- unique(rbind(temp_ext_rels,
                                  cbind(onto$external_relations[[temp_which_anc]],
                                        data.frame(height = onto$height[temp_which_anc] )) ))
  }
  temp_ext_rels <- temp_ext_rels[which(is.element(temp_ext_rels$relation, inter_onto_relations)),]
  return(temp_ext_rels)
}

# temp_cl_ids <- str_extract(dataset_list$ENCODE_HH$agg_med_norm__coldata$biosample_ontology,"CL_.[0-9]*")
# temp_cl_ids <- str_replace(temp_cl_ids,"_",":")
temp_cl_ids <- str_extract(dataset_list$ENCODE_GTEX_COMB$coldata$onto_id,"CL:[0-9]*")


temp_cl_paired_uberon_ids <- rep(NA, length(temp_cl_ids))
temp_list <- list()

# add primarily_composes (CL->UBERON) from composed_primarily_of (UBERON->CL)
for(i in 1:length(ontos$uberon$ont$id)){
  if(i %% 500 == 0){print(i)}
  temp_df <- ontos$uberon$ont$external_relations[[i]]
  if(is.null(temp_df)){next}
  temp_df[which(temp_df$relation=="composed_primarily_of" & grepl("CL:",temp_df$id)),]
  if(nrow(temp_df)==0){next}
  for(j in 1:nrow(temp_df)){
    temp_df$id[j]
    ontos$cl$ont <- add_external_relation(id=temp_df$id[j], onto=ontos$cl$ont,
                                          relation_name =  "primarily_composes(complement_of:composed_primarily_of)",
                                          relation_to_id = ontos$uberon$ont$id[i])
  }
}
###

for(i in 1:length(temp_cl_ids)){
  if(is.na(temp_cl_ids[i])){temp_list[i] <- list(NULL);next}
  temp_df <- get_onto_paired_concepts(temp_cl_ids[i],ontos$cl$ont,
                                      inter_onto_relations = c("is_a",
                                                               "part_of", #"part_of(SUPP_INV(has_part))",
                                                                "primarily_composes(complement_of:composed_primarily_of)"))
  if(is.null(temp_df)){ temp_list[i] <- list(NULL); next}
  
  ## this is a bit cludgy trying to map to most specific term between ontologies
  if(any(temp_df$relation == "part_of")){
    temp_df <- temp_df[which(temp_df$relation=="part_of"),]
    temp_list[[i]] <- temp_df[which(temp_df$height == min(temp_df$height)),]
  } else{
    temp_list[[i]] <- temp_df[which(temp_df$height == min(temp_df$height)),]
  }
  
}


for(i in 1:length(temp_list)){
  if(i %% 20 == 0){print(i)}
  if(is.null(temp_list[[i]]) || nrow(temp_list[[i]])==0){next}
  for(j in 1:nrow(temp_list[[i]])){
    if(!is.element(temp_list[[i]]$id[j],ontos$uberon$ont$id)){next}
    ontos$uberon$ont <- add_annotation(temp_list[[i]]$id[j], ontos$uberon$ont, "ehh", i,
                         transitive_relations = c("part_of", "part_of(SUPP_INV(has_part))", "is_a" ))
  }
}


names(temp_list) <- ontos$cl$ont$name[match(temp_cl_ids,ontos$cl$ont$id)]
for(i in 1:length(temp_list)){temp_list[[i]]$name <- ontos$uberon$ont$name[match(temp_list[[i]]$id, ontos$uberon$ont$id)]}

###
save.image()
```



```{r collected functions used, include=FALSE}
### slow with many samples ... prioritize for parallelization 
calc_dot_product_similarity_matrix <- function(dat) {
  colgroups <- split(1:ncol(dat), ceiling((1:ncol(dat))/ (ncol(dat)/getDoParWorkers()) ))
  dot_product_similarity_matrix <- foreach(colids=colgroups, .combine = cbind) %dopar% {
  #  dat <- dat[,colids, drop=F]
    sub_sim_mat <- matrix(0, nrow = ncol(dat), ncol = length(colids))
    for(i in 1:length(colids)){
      for(j in 1:ncol(dat)){
        which_i <- which(!is.na(dat[,colids[i]])) ## ignore NAs
        which_j <- which(!is.na(dat[,j])) ## ignore NAs
        sub_sim_mat[j,i] <- sum(dat[which_i,colids[i]] * dat[which_j,j]) /
          (norm(dat[which_i,colids[i]],"2")*norm(dat[which_j,j],"2"))
      }
    }
    sub_sim_mat
  }
  
  colnames(dot_product_similarity_matrix) <- colnames(dat)
  rownames(dot_product_similarity_matrix) <- colnames(dat)
  
  return(dot_product_similarity_matrix)
}

### uses Equation 1. from paper 
add_dist_to_parent <- function(dend, dist_to_parent=0){
  ## note: distance to parent is fed in at the start of the function
  attributes(dend) <- c(attributes(dend), dist_to_parent=dist_to_parent)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    ## distance to parent is simply the difference in height between parent and child
    dist_to_parent <- attributes(dend)$height - attributes(dend[[i]])$height 
    dend[[i]] <- add_dist_to_parent(dend[[i]], 
                                             dist_to_parent = dist_to_parent)
  }
  return(dend)
}

## this functions calculates and adds weights to dendrogram object using the 'dist_to_parent' attribute added previously
## weight_of_parent parameter exists only for recursion and should not be manually adjusted without understanding it's function
add_weights <- function(dend, weight_of_parent=0){
  weight <- (attributes(dend)$dist_to_parent / attributes(dend)$members) + weight_of_parent 
  attributes(dend) <- c(attributes(dend), weight=weight)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    dend[[i]] <- add_weights(dend[[i]], weight_of_parent=weight)
  }
  return(dend)
}

## this function returns the weights from a dendrogram object that has a "weight" attribute at leaves. Also requires the order of the vector to return based on names of leaves
get_weights <- function(dend, name_order){
  weights <- setNames(get_leaves_attr(dend,"weight"),nm=get_leaves_attr(dend,"lab") )
  weights <- weights[order(factor(names(weights),levels = name_order))]
  return(weights)
}


# function to calculate weighted zscores given matrix and vector of weights. column names of the matrix and names of the weight vector must match
calc_weighted_zscore_matrix <- function(mat, weights){
  if(any( colnames(mat) != names(weights) )){stop("WARNING: mismatch in weights names and matrix colnames order")}
  weighted_mat <- mat; weighted_mat[] <- 0
  for (i in 1:length(weights)){
    weighted_mat[,i] <- weights[i]*mat[,i]
  }
  weighted_means <- numeric(length = nrow(weighted_mat))
  sum_of_weights <- sum(weights)
  for (i in 1:nrow(weighted_mat)){
    weighted_means[i] <- sum(weighted_mat[i,]) / sum_of_weights
  }
  weighted_var <- numeric(length=nrow(mat))
  for (i in 1:nrow(mat)){
    weighted_var[i] <- Hmisc::wtd.var(mat[i,],weights=weights)
  }
  weighted_sd <- sqrt(weighted_var)
  for(i in 1:ncol(mat)){
    mat[,i] <- (mat[,i]-weighted_means)/weighted_sd
  }
  weighted_zscores <- mat
  return(weighted_zscores)
}

# weighted tau
calc_weighted_tau <- function(mat, weights){
  xhat_matrix <- matrix(nrow=nrow(mat),ncol=ncol(mat))
  te_row_maxima <- apply(mat, 1, max)
  for(j in 1:ncol(mat)){
    xhat_matrix[,j] <- mat[,j] / te_row_maxima
  }
  temp_matrix <- matrix(nrow=nrow(mat),ncol=ncol(mat))
  for (i in 1:nrow(mat)){
    temp_matrix[i,] <- weights - (xhat_matrix[i,] * weights)
  }
  tau <- numeric(length = nrow(temp_matrix))
  for (i in 1:nrow(temp_matrix)){
    temp <- sum(temp_matrix[i,]) / (sum(weights) - weights[which.max(temp_matrix[i,])])
    tau[i] <- ifelse(length(temp)==0,NA,temp)
  }
  
  ## add normalization (believe this is a numeric instability issue from dividing small numbers)
  # tau <- tau / max(tau, na.rm=T)
  ## alternative, set all > 1 to 1 (when looking at plots for different cutoffs, normalizing true 1 values causes issue)
  tau[which(tau > 1)] <- 1
  return(tau)
}


## only 1 similarity function tested for now, can make as list later
similarity_func <- function(exp_mat){
  weights <- setNames(rep(1,length(colnames(exp_mat))),colnames(exp_mat))
  calc_dot_product_similarity_matrix(calc_weighted_zscore_matrix(exp_mat, weights))
}

## only 1 clustering fucntion tested for now, can make as a list later
cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "average") ) ))}  
```

```{r}

rm(coldata, data_list_backup, mat, mat_cleaned, temp,
   temp_coldata, temp_data_list_qc, temp_df, temp_encode_coldata,
   temp_encode_mat, temp_gtex_coldata, temp_gtex_mat, temp_list,
   temp_mat, temp_time_ests)
rm(i, j, bioc_package, max_val, median_normalize, min_val,
   temp_cl_ids, temp_cl_paired_uberon_ids, temp_id, temp_rownames,
   temp_uberon_ids, temp_url, which_col, which_keep, which_max, which_min, which_rm)
save.image("./setup_w_expr_dat_and_funcs.RData")
```

### Below belong in analysis section not setup section

```{r}
temp <- tempfile()
temp_url <- "https://storage.googleapis.com/adult-gtex/bulk-gex/v8/rna-seq/GTEx_Analysis_2017-06-05_v8_RSEMv1.3.0_transcript_tpm.gct.gz"
download.file(temp_url,temp)

dataset_list$TEXP_GTEX <- list()
dataset_list$TEXP_GTEX$median_mat <- read.table( temp, skip=2, header = TRUE, sep = "\t")
unlink(temp); rm(temp)


dataset_list$TEXP_GTEX$median_mat_rowinfo <-  data.frame(transcript=dataset_list$TEXP_GTEX$median_mat$transcript_id,
                                                         gene=dataset_list$TEXP_GTEX$median_mat$gene_id)
rownames(dataset_list$TEXP_GTEX$median_mat) <- dataset_list$TEXP_GTEX$median_mat$transcript
dataset_list$TEXP_GTEX$median_mat$transcript_id <- NULL
dataset_list$TEXP_GTEX$median_mat$gene_id <- NULL

temp <- tempfile()
temp_url <- "https://storage.googleapis.com/adult-gtex/annotations/v8/metadata-files/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt"
download.file(temp_url,temp)
temp <- read.csv( temp, skip=0, header = TRUE, sep = "\t")
temp <- unique(data.frame(colname=temp$SMTSD,uberon_id=temp$SMUBRID, SAMPID=temp$SAMPID))
#temp$sim_colname <- tolower(str_remove_all(temp$colname, "[ \\.\\-\\(\\)]"))
temp$sim_idname <- str_replace_all(temp$SAMPID, "-","\\.")
temp <- temp[match(colnames(dataset_list$TEXP_GTEX$median_mat), temp$sim_idname),]
which <- which(!is.na(temp$colname))
temp <- temp[which,]
dataset_list$TEXP_GTEX$median_mat <- dataset_list$TEXP_GTEX$median_mat[,which]


dataset_list$TEXP_GTEX$median_mat_colinfo <- temp
dataset_list$TEXP_GTEX$median_mat_colinfo$sample_type <- dataset_list$TEXP_GTEX$median_mat_colinfo$colname
dataset_list$TEXP_GTEX$median_mat_colinfo$colname <- make.unique(dataset_list$TEXP_GTEX$median_mat_colinfo$colname) 
colnames(dataset_list$TEXP_GTEX$median_mat) <- dataset_list$TEXP_GTEX$median_mat_colinfo$colname

which <- which(dataset_list$TEXP_GTEX$median_mat_colinfo$uberon_id == "0002190")
temp1 <- rowMedians(as.matrix(dataset_list$TEXP_GTEX$median_mat[which,]))
temp2 <- rowMeans(dataset_list$TEXP_GTEX$median_mat[which,])


dataset_list$TEXP_GTEX$median_mat_colinfo__reduced <- unique(dataset_list$TEXP_GTEX$median_mat_colinfo[,c("sample_type","uberon_id")])
temp_uberon_ids <- unique(dataset_list$TEXP_GTEX$median_mat_colinfo$uberon_id)
temp_uberon_ids <- temp_uberon_ids[grep("EFO",temp_uberon_ids,invert = T)]
dataset_list$TEXP_GTEX$median_mat_colinfo__reduced <- dataset_list$TEXP_GTEX$median_mat_colinfo__reduced[
  match(temp_uberon_ids, dataset_list$TEXP_GTEX$median_mat_colinfo__reduced$uberon_id),
]

dataset_list$TEXP_GTEX$median_mat__reduced <- matrix(nrow = nrow(dataset_list$TEXP_GTEX$median_mat),
                                                     ncol = length(temp_uberon_ids),
                                                     dimnames = list(rownames(dataset_list$TEXP_GTEX$median_mat),
                                                                     temp_uberon_ids))
for(uberon_id in temp_uberon_ids){
  print(uberon_id)
  dataset_list$TEXP_GTEX$median_mat__reduced[,uberon_id] <- 
    rowMedians(as.matrix(dataset_list$TEXP_GTEX$median_mat[,which(dataset_list$TEXP_GTEX$median_mat_colinfo$uberon_id == uberon_id)]))
}
# data_list <- foreach(i=1:nrow(query_table) , .errorhandling = "pass") %dopar% {
#   
# }
dataset_list$TEXP_GTEX$median_mat <- dataset_list$TEXP_GTEX$median_mat__reduced
dataset_list$TEXP_GTEX$median_mat_colinfo <- dataset_list$TEXP_GTEX$median_mat_colinfo__reduced


dataset_list$TEXP_GTEX$median_mat_rowinfo$gene_id <- str_remove(dataset_list$TEXP_GTEX$median_mat_rowinfo$gene,"\\..*")
dataset_list$TEXP_GTEX$median_mat_rowinfo$gene_name <- gene_sets$genes_all_transcript_w_noncanon$external_gene_name[
  match(dataset_list$TEXP_GTEX$median_mat_rowinfo$gene_id,
        gene_sets$genes_all_transcript_w_noncanon$ensembl_gene_id)]
which <- which(is.element(dataset_list$TEXP_GTEX$median_mat_rowinfo$gene_id,
                          gene_sets$genes_all$ensembl_gene_id[gene_sets$genes_all$gene_biotype=="protein_coding"]) &
                 !is.element(dataset_list$TEXP_GTEX$median_mat_rowinfo$gene_id,
                          gene_sets$genes_all_transcript$ensembl_gene_id[gene_sets$genes_all_transcript$chromosome_name=="MT"])
                 )
dataset_list$TEXP_GTEX$median_mat_rowinfo <- dataset_list$TEXP_GTEX$median_mat_rowinfo[which,]
dataset_list$TEXP_GTEX$median_mat <- dataset_list$TEXP_GTEX$median_mat[which,]

gc()
save.image()

dataset_list$TEXP_GTEX$median_mat <- apply(dataset_list$TEXP_GTEX$median_mat, 2, FUN=function(x){ x * 1e6 /sum(x) })
dataset_list$TEXP_GTEX$median_mat <- apply(dataset_list$TEXP_GTEX$median_mat, 2, FUN=function(x){ log10(x+1) })
dataset_list$TEXP_GTEX$median_mat <- apply(dataset_list$TEXP_GTEX$median_mat, 2, FUN=function(x){ x/median(x[which(x>1e-6)]) })
```

```{r}
temp <- tempfile()
temp_url <- "https://storage.googleapis.com/adult-gtex/long-read-data/v9/long-read-RNA-seq/quantification_gencode.tpm.txt.gz"
temp <- tempfile()
download.file(temp_url,temp)

dataset_list$LR_GTEX <- list()
dataset_list$LR_GTEX$median_mat <- read.table( temp, skip=0, header = TRUE, sep = "\t")
dataset_list$LR_GTEX$median_mat_rowinfo <-  data.frame(transcript=dataset_list$LR_GTEX$median_mat$transcript)
rownames(dataset_list$LR_GTEX$median_mat) <- dataset_list$LR_GTEX$median_mat$transcript
dataset_list$LR_GTEX$median_mat$transcript <- NULL
unlink(temp); rm(temp)



temp <- tempfile() 
temp_url <- "https://storage.googleapis.com/adult-gtex/annotations/v8/metadata-files/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt"
download.file(temp_url,temp)
temp <- read.csv( temp, skip=0, header = TRUE, sep = "\t")
temp <- unique(data.frame(colname=temp$SMTSD,uberon_id=temp$SMUBRID, SAMPID=temp$SAMPID))
temp$sim_colname <- tolower(str_remove_all(temp$colname, "[ \\.\\-\\(\\)]"))
temp$sim_idname <- str_remove(str_replace_all(temp$SAMPID, "-","\\."),"\\.SM\\..*")
temp <- temp[match(str_remove(colnames(dataset_list$LR_GTEX$median_mat),"\\.SM\\..*"), temp$sim_idname),]
which <- which(!is.na(temp$colname))
temp <- temp[which,]
dataset_list$LR_GTEX$median_mat <- dataset_list$LR_GTEX$median_mat[,which]
temp$sim_idname <- temp

dataset_list$LR_GTEX$median_mat_colinfo <- temp
dataset_list$LR_GTEX$median_mat_colinfo$colname <- make.unique(dataset_list$LR_GTEX$median_mat_colinfo$colname) 
colnames(dataset_list$LR_GTEX$median_mat) <- dataset_list$LR_GTEX$median_mat_colinfo$colname

which_keep <- grep("EFO_",dataset_list$LR_GTEX$median_mat_colinfo$uberon_id,invert = T)
dataset_list$LR_GTEX$median_mat_colinfo <- dataset_list$LR_GTEX$median_mat_colinfo[which_keep,] 
dataset_list$LR_GTEX$median_mat <- dataset_list$LR_GTEX$median_mat[,which_keep]
which <- grep("UBERON:",dataset_list$LR_GTEX$median_mat_colinfo$uberon_id,invert = T)
dataset_list$LR_GTEX$median_mat_colinfo$uberon_id[which] <- paste0("UBERON:",dataset_list$LR_GTEX$median_mat_colinfo$uberon_id[which])


dataset_list$LR_GTEX$median_mat_rowinfo$gene_id <- gene_sets$genes_all_transcript_w_noncanon$ensembl_gene_id[
  match(str_remove(dataset_list$LR_GTEX$median_mat_rowinfo$transcript,"\\..*"),
        gene_sets$genes_all_transcript_w_noncanon$ensembl_transcript_id)]
dataset_list$LR_GTEX$median_mat_rowinfo$gene_name <- gene_sets$genes_all_transcript_w_noncanon$external_gene_name[
  match(str_remove(dataset_list$LR_GTEX$median_mat_rowinfo$transcript,"\\..*"),
        gene_sets$genes_all_transcript_w_noncanon$ensembl_transcript_id)]
which_keep <- which(!is.na(dataset_list$LR_GTEX$median_mat_rowinfo$gene_id))
dataset_list$LR_GTEX$median_mat <- dataset_list$LR_GTEX$median_mat[which_keep,]
dataset_list$LR_GTEX$median_mat_rowinfo <- dataset_list$LR_GTEX$median_mat_rowinfo[which_keep,]
```


