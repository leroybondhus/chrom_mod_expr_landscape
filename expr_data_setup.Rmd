---
title: "expr_data_setup"
author: "Leroy Bondhus"
date: "2023-08-20"
output: html_document
---

```{r, load libraries}
req_packages <- list(
  standard = c("dendextend","factoextra","cowplot"),
  biocmanager = c("Gviz","biomaRt")
)
for(std_package in req_packages$standard ){
  if(!require(std_package, quietly=T, character.only=T)){install.packages(std_package)}
};rm(std_package)
for(bioc_package in req_packages$biocmanager ){
  if(!require(bioc_package, quietly=T, character.only=T)){BiocManager::install(bioc_package)}
};rm(bioc_package)
rm(req_packages)

```


```{r}
if(!exists("dataset_list")){dataset_list <- list()}
registerDoParallel(detectCores()-2)
files$temp_log <- paste0(dirs$temp_data,"temp.log")
library(jsonlite)
library(httr)
library(dendextend)
library(factoextra)
library(cowplot)
```
```{r}
### look into this as supplement/alt to encode
## https://stemangiola.github.io/CuratedAtlasQueryR/
```


```{r, encode human RNA}

print(Sys.time())
# search_query <- "https://www.encodeproject.org/search/?type=Experiment&related_series.@type=ReferenceEpigenome&status=released&replicates.library.biosample.donor.organism.scientific_name=Mus+musculus&assay_title=polyA+plus+RNA-seq&frame=object&format=json&limit=all"
# 
search_query <- paste0("https://www.encodeproject.org/search/",
                       "?type=Experiment&control_type!=*&status=released&perturbed=false",
                       "&assay_title=total+RNA-seq", #&assay_title=polyA+plus+RNA-seq
                       "&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens",
                       "&format=json&limit=all")
#"https://www.encodeproject.org/search/?type=Experiment&related_series.@type=ReferenceEpigenome&status=released&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&assay_title=polyA+plus+RNA-seq&frame=object&format=json&limit=all"
query_result <- GET(search_query)
query_result <- content(query_result , "text", encoding = "UTF-8")
query_result <- fromJSON(query_result, flatten = T)
query_table <- query_result$`@graph`[!unlist(lapply(query_result$`@graph`, is.list))]

##
#data_list <- list()
#foreach(simul_pars = simul_pars_list, .final = function(x) setNames(x, names(simul_pars_list)), .errorhandling = "pass") %dopar% {
system(paste0("echo \"\" > ",files$temp_log))
data_list <- foreach(i=1:nrow(query_table) , .errorhandling = "pass") %dopar% { #nrow(query_table)
#for(i in 1:nrow(query_table)){
  #if(i %% 5 == 0){print(i)}
  system(paste0("echo \"processing: ",i, "\" >> ",files$temp_log))
  target <- paste0("https://www.encodeproject.org/",
                          query_table$accession[i],
                          "/?frame=embedded&format=json")
  target <- GET(target)
  target_result <- content(target, "text", encoding = "UTF-8")
  target_result <- fromJSON(target_result, flatten = TRUE)
  temp_gene_anno <-  unique(target_result$files$genome_annotation)
  temp_gene_anno <- temp_gene_anno[grep("ENSEMBL", temp_gene_anno,invert = T)]
  which <- which(target_result$files$file_format=="tsv" &
                 target_result$files$output_type=="gene quantifications" &
                 grepl(max(as.numeric(str_remove_all(temp_gene_anno,"[a-zA-Z]")),na.rm = T),
                       target_result$files$genome_annotation) &
                 target_result$files$status == "released")
  if(length(which)==0){next}
  
  
  
  which_cols <- c("accession", "href","biosample_ontology",
                "biological_replicates", "technical_replicates",
                "biological_replicates_formatted", "donors",
                "dataset")
  gene_quant_files <- target_result$files[which,which_cols]
  gene_quant_files[,which(unlist(lapply(gene_quant_files, is.list)))] <- 
    sapply(gene_quant_files[,which(unlist(lapply(gene_quant_files, is.list)))], paste )
  target_coldata <- cbind(query_table[i,], gene_quant_files)
  target_coldata$life_stage_age <- ifelse(is.null(target_result$life_stage_age),NA,target_result$life_stage_age)
  
  if(all(is.na(target_coldata$life_stage_age))){
    temp_pattern = paste0("[0-9-]+ day|day [0-9-]+|[0-9-]+ week|[0-9-]+ month|[0-9-]+ year",
                           "|embryo|fetus|neonat|newborn|child|teen|adult")
    target_coldata$life_stage_age <- paste0(unlist(str_extract_all(tolower(query_table$biosample_summary[i]),temp_pattern)),collapse = ",")
  }
  
  
  for(j in 1:nrow(target_coldata)){
    temp <- tempfile()
    download.file(paste0("https://www.encodeproject.org/",target_coldata$href[j]), temp)
    temp_data <- read.table(temp, skip = 0, header = TRUE, sep = "\t")
    temp_data <- temp_data[grep("PAR_Y",temp_data$gene_id, invert=T),]
    temp_list <- list(TPM = data.frame(TPM=temp_data$TPM),
                      coldata = cbind(target_coldata[j,], read_count=sum(temp_data$posterior_mean_count) ) )
    rownames(temp_list$TPM) <- str_remove(temp_data$gene_id,"\\..*")
  }
  temp_list
}

data_list <- data_list[which(sapply(data_list, function(x){!all(names(x)==c("message","call"))}))]

temp_data_list_qc <- data.frame(tpm_nrow=numeric(length=length(data_list)),
                                tpm_ncol=numeric(length=length(data_list)),
                                coldata_nrow=numeric(length=length(data_list)))
temp_rownames <- character()
for(i in 1:length(data_list)){
  temp_data_list_qc$tpm_nrow[i] <- nrow(data_list[[i]]$TPM)
  temp_data_list_qc$tpm_ncol[i] <- ncol(data_list[[i]]$TPM)
  temp_data_list_qc$coldata_nrow[i] <- nrow(data_list[[i]]$coldata)
  temp_rownames <- unique(c(temp_rownames,rownames(data_list[[i]]$TPM)))
}
for(i in 1:length(data_list)){
  temp_missing_rownames <- setdiff(temp_rownames, rownames(data_list[[i]]$TPM))
  if(length(temp_missing_rownames)==0){next}
  temp_df <- data.frame(TPM = rep(0, length(temp_missing_rownames)))
  rownames(temp_df) <- temp_missing_rownames
  data_list[[i]]$TPM <- rbind(data_list[[i]]$TPM, temp_df)
}
for(i in 1:length(data_list)){
  temp_data_list_qc$tpm_nrow[i] <- nrow(data_list[[i]]$TPM)
  temp_data_list_qc$tpm_ncol[i] <- ncol(data_list[[i]]$TPM)
  temp_data_list_qc$coldata_nrow[i] <- nrow(data_list[[i]]$coldata)
}
#### fix dim mismatch issue for human data here ..... 
if( nrow(unique(temp_data_list_qc)) != 1){stop("dimension mismatch between objects")}

data_list_concat <- data_list[[1]]
for(i in 2:length(data_list)){
  data_list_concat$TPM <- cbind(data_list_concat$TPM, data_list[[i]]$TPM)
  data_list_concat$coldata <- rbind(data_list_concat$coldata, data_list[[i]]$coldata)
}
data_list_concat$coldata <- as.data.frame(data_list_concat$coldata)

dataset_list$ENCODE_HH <- list(mat = data_list_concat$TPM, coldata=data_list_concat$coldata)
which <- grep("_UBERON_|_CL_", dataset_list$ENCODE_HH$coldata$biosample_ontology)
dataset_list$ENCODE_HH$mat <- dataset_list$ENCODE_HH$mat[,which]
dataset_list$ENCODE_HH$coldata <- dataset_list$ENCODE_HH$coldata[which,]

rm(data_list, query_result, query_table, temp_data, temp_df,
   data_list_concat, temp_missing_rownames, search_query, temp_rownames)


### merge common biosample types (e.g. get median expression for all)
print(Sys.time())
save.image("./post_full_mat.Rdata") ## next aggregate common samples into median expr values
```


```{r}
ensembl <- useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl")
genes <- getBM(attributes=c('chromosome_name','start_position','end_position','hgnc_symbol', 'ensembl_gene_id','gene_biotype'),
                 filters = list('biotype'=c('protein_coding','lincRNA')),
                 mart = ensembl, useCache = F) 
genes <- genes[which(is.element(genes$chromosome_name, c(1:22, "X", "Y", "MT")) & genes$ensembl_gene_id != "" ) ,]
gene_sets$for_hh_expr <- genes
rm(genes)
```

```{r}
# mat <- dataset_list$ENCODE_HH$mat[,ehh]
# coldata <- dataset_list$ENCODE_HH$coldata[ehh,]
# colnames(mat) <- make.unique(coldata$accession)

### select rows (e.g. remove mitochondria)
which <- which(gene_sets$for_hh_expr$chromosome_name != "MT" )
mat <- dataset_list$ENCODE_HH$mat
coldata <- dataset_list$ENCODE_HH$coldata
colnames(mat) <- make.unique(coldata$accession)

mat_cleaned <- mat[which(is.element(rownames(mat),
                                    gene_sets$for_hh_expr$ensembl_gene_id[which])),]
### normalize : re-calculate TPM, log10+1 transform, median normalize
for(i in 1:ncol(mat_cleaned)){
  mat_cleaned[,i] <- (mat_cleaned[,i]*1e6 / sum(mat_cleaned[,i]))
  ## set all very low counts to zero to avoid variable read depth issues
  mat_cleaned[,i] [which(mat_cleaned[,i]  < 1)] <- 0
  mat_cleaned[,i] <- (mat_cleaned[,i]*1e6 / sum(mat_cleaned[,i]))
}
mat_cleaned <- log10(mat_cleaned+1)
median_normalize <- TRUE
if(median_normalize){
  for(i in 1:ncol(mat_cleaned)){
    mat_cleaned[,i] <- mat_cleaned[,i] / median(mat_cleaned[,i][which(mat_cleaned[,i] > 0)])
  }
}
colnames(mat_cleaned) <- make.unique(
  dataset_list$ENCODE_HH$coldata$biosample_ontology.term_name)

dataset_list$ENCODE_HH$median_norm_mat <- mat_cleaned
```



```{r, preprocesss datasets}
## seperate out different assay types.... probs should do this earlier..

### aggregate on common 

convert_str_to_rel_age <- function(in_str){
  base_age_min <- base_age_max <- 0
  is_neonat <- grepl("neonat|newborn",tolower(in_str))
  is_embryo <- grepl("embryo",tolower(in_str))
  if(!is_embryo){
    base_age_min <- 30*9
    base_age_max <- 30*9
  }
  num_values <- as.numeric(unlist(str_extract_all(in_str, "[0-9]+")))
  quant_values <- unlist(str_extract_all(tolower(in_str), "day|week|month|year"))
  if(length(quant_values)==1){quant_values <- rep(quant_values, length(num_values))}
  
  quant_values[which(quant_values=="day")] <- 1
  quant_values[which(quant_values=="week")] <- 7
  quant_values[which(quant_values=="month")] <- 30
  quant_values[which(quant_values=="year")] <- 365
  quant_values <- as.numeric(quant_values)
  if(length(quant_values) != length(num_values) | length(num_values)==0){
    quant_values<-1; num_values<-0
    if(is_embryo){
      base_age_max=30*9-1
    }else if(!is_neonat){
      return(data.frame(min_age_est=NA,
                        mean_age_est=NA,
                        max_age_est=NA))
    }
  }
  max_age_est <- max(quant_values*num_values+base_age_max)
  if(is_neonat &  max_age_est < 30*9){
    max_age_est <- 30*9
  }
  return(data.frame(min_age_est=min(quant_values*num_values+base_age_min),
              mean_age_est=mean(quant_values*num_values+(base_age_min+base_age_max)/2 ),
              max_age_est=max_age_est ))
}

convert_range_to_ordered_factor <- function(in_str){
  df <- unique(str_split_fixed(in_str,"-",2))
  df <- df[order(as.numeric(df[,1]),as.numeric(df[,2])),]
  out_fctr <- paste(df[,1],df[,2],sep="-")
  out_fctr <- str_replace(out_fctr, "-$|^-","")
  return(factor(in_str, levels=out_fctr))
}

coldata <- dataset_list$ENCODE_HH$coldata
mat <- dataset_list$ENCODE_HH$median_norm_mat

temp_time_ests <- NULL
for(i in 1:length(coldata$life_stage_age)){
   temp_time_ests <- rbind(temp_time_ests,
                           convert_str_to_rel_age(coldata$life_stage_age[i]))
}
coldata$min_age_est <- temp_time_ests$min_age_est
coldata$max_age_est <- temp_time_ests$max_age_est


coldata <- coldata[,c("assay_term_name","biosample_ontology","biosample_ontology.term_name","min_age_est","max_age_est")]

age_group_cuts <- c(0,2^c(0:16))

coldata$age_group <- -1
for(i in 1:nrow(coldata)){
  min_val <- coldata$min_age_est[i]
  which_min <- which( min_val < age_group_cuts[2:length(age_group_cuts)] & 
                        min_val >= age_group_cuts[1:(length(age_group_cuts)-1)])
  max_val <- coldata$max_age_est[i]
  which_max <- which( max_val < age_group_cuts[2:length(age_group_cuts)] & 
                        max_val >= age_group_cuts[1:(length(age_group_cuts)-1)])+1
  coldata$age_group[i] <- paste0(c(age_group_cuts[which_min],age_group_cuts[which_max]),collapse = "-")
}


coldata$age_group <- convert_range_to_ordered_factor(coldata$age_group)

coldata$min_age_est <- NULL
coldata$max_age_est <- NULL
coldata$onto_w_age <-
  paste0(coldata$biosample_ontology, coldata$age_group)

temp_coldata <- unique(coldata)
temp_mat <- matrix(nrow = nrow(mat),ncol=nrow(temp_coldata),dimnames = list(rownames(mat),NULL)) 
for(i in 1:nrow(temp_coldata)){
  which_col <- which(coldata$onto_w_age == temp_coldata$onto_w_age[i])
  temp_mat[,i] <- rowMeans(mat[,which_col,drop=F])
}

dataset_list$ENCODE_HH$agg_med_norm__mat <- temp_mat
dataset_list$ENCODE_HH$agg_med_norm__coldata <- temp_coldata
```


```{r, embed in ontology}

### add cardiac ventricles and cardiac atria as proxy for cardiac muscle tissue
temp_id <- ontos$uberon$ont$id[which(ontos$uberon$ont$name=="cardiac muscle tissue")]
which <- which(ontos$uberon$ont$name == "cardiac atrium")
ontos$uberon$ont$relations[[which]] <- unique(rbind(ontos$uberon$ont$relations[[which]],
                                                    data.frame(relation="proxy_for(SUPP)",id=temp_id)))
which <- which(ontos$uberon$ont$name == "cardiac ventricle")
ontos$uberon$ont$relations[[which]] <- unique(rbind(ontos$uberon$ont$relations[[which]],
                                                    data.frame(relation="proxy_for(SUPP)",id=temp_id)))
temp_id <- ontos$uberon$ont$id[which(ontos$uberon$ont$name=="skeletal muscle tissue")]
which <- which(ontos$uberon$ont$name == "skeletal muscle organ")
ontos$uberon$ont$relations[[which]] <- unique(rbind(ontos$uberon$ont$relations[[which]],
                                                    data.frame(relation="proxy_for(SUPP)",id=temp_id)))

#onto <- ontos$uberon$ont

### is_a, part_of, develops_from ...

#### development lineage building pseudocode
### if x develops_from y , x --> y, else if x is_a y, go_tzo y, repeat. ##  
### 
### annotate ontology with is_a and part_of
ontos$uberon$ont <- add_inverse_relation(ontos$uberon$ont, "develops_from","devolops_into(SUPP_INV(develops_from))")


temp_uberon_ids <- str_extract(dataset_list$ENCODE_HH$agg_med_norm__coldata$biosample_ontology,"UBERON.[0-9]*")
temp_uberon_ids <- str_replace(temp_uberon_ids,"_",":")


ontos$uberon$ont$ehh <- vector("list", length(ontos$uberon$ont$id))
for(i in 1:length(temp_uberon_ids)){
  if(i %% 100 == 0){print(i)}
  if(is.na(temp_uberon_ids[i])){next}
  ontos$uberon$ont <- add_annotation(temp_uberon_ids[i], ontos$uberon$ont, "ehh", i,
                         transitive_relations = c("part_of",  "is_a", "proxy_for(SUPP)" ))  
}


temp_cl_ids <- str_extract(dataset_list$ENCODE_HH$agg_med_norm__coldata$biosample_ontology,"CL.[0-9]*")
temp_cl_ids <- str_replace(temp_cl_ids,"_",":")


ontos$cl$ont$ehh <- vector("list", length(ontos$cl$ont$id))
for(i in 1:length(temp_cl_ids)){
  if(i %% 100 == 0){print(i)}
  if(is.na(temp_cl_ids[i])){next}
  ontos$cl$ont <- add_annotation(temp_cl_ids[i], ontos$cl$ont, "ehh", i,
                         transitive_relations = c("part_of",  "is_a", "proxy_for(SUPP)" ))  
}



### map cells to uberon concept if "CL is part_of UBERON"
## modified to include depth of ancestor
get_onto_paired_concepts <- function(id, onto, inter_onto_relations=c("is_a","part_of")){
  which <- which(onto$id == id)
  temp_anc <- get_ancestors(id,onto)
  temp_ext_rels <- c()
  for(i in 1:length(temp_anc)){
    temp_which_anc <- which(onto$id == temp_anc[i])
    if(is.null(onto$external_relations[[temp_which_anc]])){next}
    temp_ext_rels <- unique(rbind(temp_ext_rels,
                                  cbind(onto$external_relations[[temp_which_anc]],
                                        data.frame(height = onto$height[temp_which_anc] )) ))
  }
  temp_ext_rels <- temp_ext_rels[which(is.element(temp_ext_rels$relation, inter_onto_relations)),]
  return(temp_ext_rels)
}

temp_cl_ids <- str_extract(dataset_list$ENCODE_HH$agg_med_norm__coldata$biosample_ontology,"CL_.[0-9]*")
temp_cl_ids <- str_replace(temp_cl_ids,"_",":")
temp_cl_paired_uberon_ids <- rep(NA, length(temp_cl_ids))
temp_list <- list()

# add primarily_composes (CL->UBERON) from composed_primarily_of (UBERON->CL)
for(i in 1:length(ontos$uberon$ont$id)){
  if(i %% 500 == 0){print(i)}
  temp_df <- ontos$uberon$ont$external_relations[[i]]
  if(is.null(temp_df)){next}
  temp_df[which(temp_df$relation=="composed_primarily_of" & grepl("CL:",temp_df$id)),]
  if(nrow(temp_df)==0){next}
  for(j in 1:nrow(temp_df)){
    temp_df$id[j]
    ontos$cl$ont <- add_external_relation(id=temp_df$id[j], onto=ontos$cl$ont,
                                          relation_name =  "primarily_composes(complement_of:composed_primarily_of)",
                                          relation_to_id = ontos$uberon$ont$id[i])
  }
}
###

for(i in 1:length(temp_cl_ids)){
  if(is.na(temp_cl_ids[i])){temp_list[i] <- list(NULL);next}
  temp_df <- get_onto_paired_concepts(temp_cl_ids[i],ontos$cl$ont,
                                      inter_onto_relations = c("is_a",
                                                               "part_of", #"part_of(SUPP_INV(has_part))",
                                                                "primarily_composes(complement_of:composed_primarily_of)"))
  if(is.null(temp_df)){ temp_list[i] <- list(NULL); next}
  
  ## this is a bit cludgy trying to map to most specific term between ontologies
  if(any(temp_df$relation == "part_of")){
    temp_df <- temp_df[which(temp_df$relation=="part_of"),]
    temp_list[[i]] <- temp_df[which(temp_df$height == min(temp_df$height)),]
  } else{
    temp_list[[i]] <- temp_df[which(temp_df$height == min(temp_df$height)),]
  }
  
}


for(i in 1:length(temp_list)){
  if(i %% 20 == 0){print(i)}
  if(is.null(temp_list[[i]]) || nrow(temp_list[[i]])==0){next}
  for(j in 1:nrow(temp_list[[i]])){
    if(!is.element(temp_list[[i]]$id[j],ontos$uberon$ont$id)){next}
    ontos$uberon$ont <- add_annotation(temp_list[[i]]$id[j], ontos$uberon$ont, "ehh", i,
                         transitive_relations = c("part_of", "part_of(SUPP_INV(has_part))", "is_a" ))
  }
}


names(temp_list) <- ontos$cl$ont$name[match(temp_cl_ids,ontos$cl$ont$id)]
for(i in 1:length(temp_list)){temp_list[[i]]$name <- ontos$uberon$ont$name[match(temp_list[[i]]$id, ontos$uberon$ont$id)]}

###
save.image("./setup_w_expr_dat.RData")
```



```{r collected functions used, include=FALSE}
### slow with many samples ... prioritize for parallelization 
calc_dot_product_similarity_matrix <- function(dat) {
  colgroups <- split(1:ncol(dat), ceiling((1:ncol(dat))/ (ncol(dat)/getDoParWorkers()) ))
  dot_product_similarity_matrix <- foreach(colids=colgroups, .combine = cbind) %dopar% {
  #  dat <- dat[,colids, drop=F]
    sub_sim_mat <- matrix(0, nrow = ncol(dat), ncol = length(colids))
    for(i in 1:length(colids)){
      for(j in 1:ncol(dat)){
        which_i <- which(!is.na(dat[,colids[i]])) ## ignore NAs
        which_j <- which(!is.na(dat[,j])) ## ignore NAs
        sub_sim_mat[j,i] <- sum(dat[which_i,colids[i]] * dat[which_j,j]) /
          (norm(dat[which_i,colids[i]],"2")*norm(dat[which_j,j],"2"))
      }
    }
    sub_sim_mat
  }
  
  colnames(dot_product_similarity_matrix) <- colnames(dat)
  rownames(dot_product_similarity_matrix) <- colnames(dat)
  
  return(dot_product_similarity_matrix)
}

### uses Equation 1. from paper 
add_dist_to_parent <- function(dend, dist_to_parent=0){
  ## note: distance to parent is fed in at the start of the function
  attributes(dend) <- c(attributes(dend), dist_to_parent=dist_to_parent)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    ## distance to parent is simply the difference in height between parent and child
    dist_to_parent <- attributes(dend)$height - attributes(dend[[i]])$height 
    dend[[i]] <- add_dist_to_parent(dend[[i]], 
                                             dist_to_parent = dist_to_parent)
  }
  return(dend)
}

## this functions calculates and adds weights to dendrogram object using the 'dist_to_parent' attribute added previously
## weight_of_parent parameter exists only for recursion and should not be manually adjusted without understanding it's function
add_weights <- function(dend, weight_of_parent=0){
  weight <- (attributes(dend)$dist_to_parent / attributes(dend)$members) + weight_of_parent 
  attributes(dend) <- c(attributes(dend), weight=weight)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    dend[[i]] <- add_weights(dend[[i]], weight_of_parent=weight)
  }
  return(dend)
}

## this function returns the weights from a dendrogram object that has a "weight" attribute at leaves. Also requires the order of the vector to return based on names of leaves
get_weights <- function(dend, name_order){
  weights <- setNames(get_leaves_attr(dend,"weight"),nm=get_leaves_attr(dend,"lab") )
  weights <- weights[order(factor(names(weights),levels = name_order))]
  return(weights)
}


# function to calculate weighted zscores given matrix and vector of weights. column names of the matrix and names of the weight vector must match
calc_weighted_zscore_matrix <- function(mat, weights){
  if(any( colnames(mat) != names(weights) )){stop("WARNING: mismatch in weights names and matrix colnames order")}
  weighted_mat <- mat; weighted_mat[] <- 0
  for (i in 1:length(weights)){
    weighted_mat[,i] <- weights[i]*mat[,i]
  }
  weighted_means <- numeric(length = nrow(weighted_mat))
  sum_of_weights <- sum(weights)
  for (i in 1:nrow(weighted_mat)){
    weighted_means[i] <- sum(weighted_mat[i,]) / sum_of_weights
  }
  weighted_var <- numeric(length=nrow(mat))
  for (i in 1:nrow(mat)){
    weighted_var[i] <- Hmisc::wtd.var(mat[i,],weights=weights)
  }
  weighted_sd <- sqrt(weighted_var)
  for(i in 1:ncol(mat)){
    mat[,i] <- (mat[,i]-weighted_means)/weighted_sd
  }
  weighted_zscores <- mat
  return(weighted_zscores)
}

# weighted tau
calc_weighted_tau <- function(mat, weights){
  xhat_matrix <- matrix(nrow=nrow(mat),ncol=ncol(mat))
  te_row_maxima <- apply(mat, 1, max)
  for(j in 1:ncol(mat)){
    xhat_matrix[,j] <- mat[,j] / te_row_maxima
  }
  temp_matrix <- matrix(nrow=nrow(mat),ncol=ncol(mat))
  for (i in 1:nrow(mat)){
    temp_matrix[i,] <- weights - (xhat_matrix[i,] * weights)
  }
  tau <- numeric(length = nrow(temp_matrix))
  for (i in 1:nrow(temp_matrix)){
    temp <- sum(temp_matrix[i,]) / (sum(weights) - weights[which.max(temp_matrix[i,])])
    tau[i] <- ifelse(length(temp)==0,NA,temp)
  }
  
  ## add normalization (believe this is a numeric instability issue from dividing small numbers)
  # tau <- tau / max(tau, na.rm=T)
  ## alternative, set all > 1 to 1 (when looking at plots for different cutoffs, normalizing true 1 values causes issue)
  tau[which(tau > 1)] <- 1
  return(tau)
}


## only 1 similarity function tested for now, can make as list later
similarity_func <- function(exp_mat){
  weights <- setNames(rep(1,length(colnames(exp_mat))),colnames(exp_mat))
  calc_dot_product_similarity_matrix(calc_weighted_zscore_matrix(exp_mat, weights))
}

## only 1 clustering fucntion tested for now, can make as a list later
cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "average") ) ))}  
```

```{r}
save.image("./setup_w_expr_dat_and_funcs.RData")
```

### Below belong in analysis section not setup section














<!-- ```{r} -->

<!-- temp_df <- get_desc_summary_table(id=onto$id[grep("^mesoderm-derived",onto$name)], -->
<!--                                   onto=onto, transitive_relations = c("has_part(SUPP_INV(part_of))")) -->

<!-- ##### what ontological concept has greatest divergence -->
<!-- ##### within concept low variance, between concept high variance -->
<!-- ### for kat6a -->
<!-- ### for kat6 -->
<!-- ### for kat -->
<!-- ### for chrom  -->

<!-- temp_genes <- gene_sets$genes_all$ensembl_gene_id[grep("KAT6A|KAT6B",gene_sets$genes_all$external_gene_name)] -->
<!-- temp_gene_summary_df <- matrix(nrow = length(onto$id), ncol=length(temp_genes), -->
<!--                                dimnames = list(onto$id, temp_genes)) -->
<!-- temp_list <- list(means=temp_gene_summary_df, -->
<!--                   sds=temp_gene_summary_df, -->
<!--                   log2fc=temp_gene_summary_df) -->

<!-- for(i in 1:length(onto$id)){ -->
<!--   if(i %% 500 == 0){print(i)} -->
<!--   if(is.null(onto$ehh_summary_stats$mean_internal[[i]])){next} -->
<!--   temp_list$means[i,temp_genes] <- onto$ehh_summary_stats$mean_internal[[i]][temp_genes] -->
<!--   temp_list$sds[i,temp_genes] <- onto$ehh_summary_stats$sd_internal[[i]][temp_genes] -->
<!--   temp_list$log2fc[i,temp_genes] <- log2(onto$ehh_summary_stats$mean_internal[[i]][temp_genes] /  -->
<!--                                  onto$ehh_summary_stats$mean_external[[i]][temp_genes]) -->
<!-- } -->

<!-- ##### classify genes by ubiquitous v specific -->
<!-- ``` -->



<!-- ```{r} -->


<!-- # specificity_func <- specificity_measures$funcs[[measure]] -->
<!-- # dot_sim <- similarity_func(exp_mat[,which]) -->
<!-- # sim_tree <- cluster_func(dot_sim) -->
<!-- # weights <- get_weights(sim_tree, colnames(exp_mat)[which]) -->
<!-- # if(f_or_w == "flat"){weights[] <- 1} -->
<!-- # balanced <- specificity_func(exp_mat[,which], weights) -->



<!-- ### sandox - determine reasonable summary analysis pipeline -->

<!-- onto_name <- "mesoderm-derived structure" -->
<!-- onto_id <- onto$id[which(onto$name == onto_name)] -->
<!-- ehh <- onto$ehh[[which(onto$id==onto_id)]] -->

<!-- mat <- dataset_list$ENCODE_HH$agg_med_norm__mat[,ehh] -->
<!-- coldata <- dataset_list$ENCODE_HH$agg_med_norm__coldata[ehh,] -->
<!-- colnames(mat) <- make.unique(paste0(coldata$biosample_ontology.term_name,":",coldata$age_group)) -->
<!-- ### perform similarity reweighting  -->

<!-- dot_sim <- similarity_func(mat) -->
<!-- rownames(dot_sim) <- colnames(dot_sim) <- colnames(mat)  -->

<!-- sim_tree <- cluster_func(dot_sim) -->
<!-- weights <- get_weights(sim_tree, colnames(mat)) -->
<!-- #### .... what we want here rn is also just a weighted mean and stdev for the ontology term (?) -->
<!-- #### .... this branches off here from what specificty was about.. can also measure specificity but.. -->
<!-- #### .... not goal rn...... -->
<!-- # balanced <- calc_weighted_zscore_matrix(mat_cleaned, weights) -->

<!-- weighted_means <- apply(mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.mean(x, weights=weights)}) -->
<!-- weighted_sds <- apply(mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.var(x, weights=weights)}) -->


<!-- res.pca <- prcomp(t(mat)) -->
<!-- fviz_eig(res.pca) -->
<!-- fviz_pca_ind(res.pca, repel = TRUE) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- onto <- ontos$uberon$ont -->
<!-- ### PCA -->
<!-- ### HEATMAP w CLUSTERING  -->
<!-- ### SPECIFICITY -->

<!-- ###process### ALL BIOSAMPLE -->
<!-- ###process### ALL MESODERM -->
<!-- ###process### ALL HEART -->
<!-- ##standby## iterate over set of dataset/subsets -> ALL_GENE v CHROM_GENE -->
<!-- ##standby## iterate over set of dataset/subsets -> ALL_GENE v EACH(CHROM_GENE_SUBSET) -->
<!-- ### HEART -->
<!-- ### HEART LATERALITY_GENE -->
<!-- ### HEART CHROM_GENE -->


<!-- onto_terms <- c("anatomical entity","mesoderm-derived structure","heart") -->
<!-- #gene_domain_names <- c("all","all_chrom_modifiers")  -->
<!-- #gene_set_names <- c("all","all_chrom_modifiers","EACH(chrom_subset)","laterality","CHD") -->

<!-- gss <- gene_sets$human_chromatin_modifiers$gene_subsets -->
<!-- gss$all <- gene_sets$genes_all$ensembl_gene_id -->
<!-- gene_domain_names <- c("all","all_chrom_modifiers")  -->
<!-- gene_set_names <- sort(names(gss)) -->


<!-- ehh_mat <- dataset_list$ENCODE_HH$agg_med_norm__mat -->
<!-- rownames(ehh_mat) <- rownames(dataset_list$ENCODE_HH$median_norm_mat) -->
<!-- ehh_coldata <- dataset_list$ENCODE_HH$agg_med_norm__coldata -->



<!-- dirs$scratch_figures <- paste0(dirs$figures,"scratch/") -->
<!-- if(!dir.exists(dirs$scratch_figures)){dir.create(dirs$scratch_figures)} -->

<!-- for(onto_term_index in 1:length(onto_terms)){ -->
<!--   for(gene_set_name_index in c(1,2,7)){ #length(gene_set_names)){ -->
<!--     base_filename_part <- paste0(gene_set_names[gene_set_name_index],"__", -->
<!--                        str_remove(onto$id[[which(onto$name==onto_terms[onto_term_index])]], ":")) -->

<!--     temp_cols <- onto$ehh[[which(onto$name==onto_terms[onto_term_index])]] -->
<!--     temp_rows <- which(is.element(rownames(ehh_mat),gss[[gene_set_names[gene_set_name_index]]])) -->
<!--     temp_mat <- ehh_mat[temp_rows,temp_cols] -->
<!--     temp_coldata <- ehh_coldata[temp_cols,] -->

<!--     colnames(temp_mat) <- make.unique(paste0(temp_coldata$biosample_ontology.term_name,":",temp_coldata$age_group)) -->
<!--     ### perform similarity reweighting  -->

<!--     dot_sim <- similarity_func(temp_mat) -->
<!--     rownames(dot_sim) <- colnames(dot_sim) <- colnames(temp_mat)  -->
<!--     sim_tree <- cluster_func(dot_sim) -->
<!--     weights <- get_weights(sim_tree, colnames(temp_mat)) -->

<!--     weighted_means <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.mean(x, weights=weights)}) -->
<!--     weighted_sds <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.var(x, weights=weights)}) -->


<!--     res.pca <- prcomp(t(temp_mat)) -->
<!--     fviz_eig(res.pca) -->
<!--     fviz_pca_ind(res.pca,axes = c(1,2),repel = TRUE, labelsize=3)   -->
<!--     filename <- paste0(dirs$scratch_figures,"pc12__",base_filename_part, ".png" ) -->
<!--     ggsave(filename, bg = 'white') -->
<!--     fviz_pca_ind(res.pca,axes = c(2,3),repel = TRUE, labelsize=3) -->
<!--     filename <- paste0(dirs$scratch_figures,"pc23__",base_filename_part, ".png" ) -->
<!--     ggsave(filename, bg = 'white') -->
<!--     fviz_pca_ind(res.pca,axes = c(3,4),repel = TRUE, labelsize=3) -->
<!--     filename <- paste0(dirs$scratch_figures,"pc34__",base_filename_part, ".png" ) -->
<!--     ggsave(filename, bg = 'white') -->

<!--     filename <- paste0(dirs$scratch_figures,"heatmap__",base_filename_part, ".png" ) -->
<!--     png(filename = filename, width=10,height=8,res=300,units = "in") -->
<!--     heatmap(t(temp_mat),scale="none") -->
<!--     dev.off() -->
<!--     ### PCA -->
<!--     ### HEATMAP w CLUSTERING  -->
<!--     ### SPECIFICITY -->

<!--   } -->
<!-- } -->


<!-- length(onto$ehh[[which(onto$name==onto_terms[1])]]) -->
<!-- length(onto$ehh[[which(onto$name==onto_terms[2])]]) -->
<!-- length(onto$ehh[[which(onto$name==onto_terms[3])]]) -->






<!-- ###### ALL BIOSAMPLE (ENCODE) -->
<!-- ###### ALL BRAIN (ENCODE) -->
<!-- ##### DEVELOPMENTAL TRAJECTORY (BRAINSPAN) w SUPP COMPARE ENCODE w BRAINSPAN -->
<!-- ### BRAIN -->
<!-- ### SYNDROME ASSOCIATED w w/o CHROM -->
<!-- ### NEURODEV ASSOCIATED w w/o CHROM -->
<!-- ### AUTISM ASSOCIATED w w/o CHROM -->



<!-- ######### HOW TO COMPARE VAR ALL v VAR CHROM ??  -->

<!-- ``` -->


<!-- <!-- ```{r} --> -->
<!-- <!-- onto <- ontos$uberon$ont --> -->
<!-- <!-- ## TO DO :: Compare to permutations ::   --> -->
<!-- <!-- onto_name <- "mesoderm-derived structure" --> -->
<!-- <!-- onto_id <- onto$id[which(onto$name == onto_name)] --> -->
<!-- <!-- ehh_1 <- onto$ehh[[which(onto$id==onto_id)]] --> -->
<!-- <!-- onto_name <- "endoderm-derived structure" --> -->
<!-- <!-- onto_id <- onto$id[which(onto$name == onto_name)] --> -->
<!-- <!-- ehh_2 <- onto$ehh[[which(onto$id==onto_id)]] --> -->
<!-- <!-- onto_name <- "ectoderm-derived structure" --> -->
<!-- <!-- onto_id <- onto$id[which(onto$name == onto_name)] --> -->
<!-- <!-- ehh_3 <- onto$ehh[[which(onto$id==onto_id)]] --> -->
<!-- <!-- ### perform similarity reweighting  --> -->



<!-- <!-- temp_mat <- dataset_list$ENCODE_HH$agg_med_norm__mat[,ehh_1] --> -->
<!-- <!-- temp_coldata <- dataset_list$ENCODE_HH$agg_med_norm__coldata[ehh_1,]  --> -->
<!-- <!-- colnames(temp_mat) <- make.unique(paste0(temp_coldata$biosample_ontology.term_name,":",temp_coldata$age_group)) --> -->
<!-- <!-- rownames(temp_mat) <- rownames(dataset_list$ENCODE_HH$median_norm_mat) --> -->

<!-- <!-- dot_sim <- similarity_func(temp_mat) --> -->
<!-- <!-- sim_tree <- cluster_func(dot_sim) --> -->
<!-- <!-- weights <- get_weights(sim_tree, colnames(temp_mat)) --> -->
<!-- <!-- weighted_means_1 <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.mean(x, weights=weights)}) --> -->
<!-- <!-- weighted_sds_1 <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.var(x, weights=weights)}) --> -->


<!-- <!-- df1 <- data.frame(biosample = temp_coldata$biosample_ontology.term_name, --> -->
<!-- <!--                  weights = weights) --> -->

<!-- <!-- ggplot(df1, aes(x=biosample))+ --> -->
<!-- <!--   geom_bar()+ --> -->
<!-- <!--   theme(axis.text.x  = element_text(angle = 90, vjust = 0.5, hjust=1)) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__meso_biosample_count.png")) --> -->

<!-- <!-- ggplot(df1, aes(x=biosample, y=weights))+ --> -->
<!-- <!--   geom_boxplot()+ --> -->
<!-- <!--   geom_point(aes(color=biosample),show.legend = F)+ --> -->
<!-- <!--   theme(axis.text.x  = element_text(angle = 90, vjust = 0.5, hjust=1)) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__meso_weights.png")) --> -->

<!-- <!-- aggregate(df1$weights, by=list(df1$biosample), FUN=sum) --> -->

<!-- <!-- temp_df <- aggregate(df1$weights, by=list(df1$biosample), FUN=sum)  --> -->
<!-- <!-- colnames(temp_df) <- c("biosample", "sum_of_weights") --> -->
<!-- <!-- ggplot(temp_df, aes(x=biosample, y=sum_of_weights))+ --> -->
<!-- <!--   geom_bar(stat="identity")+ --> -->
<!-- <!--   theme(axis.text.x  = element_text(angle = 90, vjust = 0.5, hjust=1)) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__meso_biosample_sum_of_weights.png")) --> -->

<!-- <!-- filename <- paste0(dirs$figures,"RD__meso_biosample_sim.png") --> -->
<!-- <!-- png(filename = filename, width=10,height=8,res=300,units = "in") --> -->
<!-- <!-- heatmap(dot_sim) --> -->
<!-- <!-- dev.off() --> -->


<!-- <!-- temp_mat <- dataset_list$ENCODE_HH$agg_med_norm__mat[,ehh_2] --> -->
<!-- <!-- temp_coldata <- dataset_list$ENCODE_HH$agg_med_norm__coldata[ehh_2,]  --> -->
<!-- <!-- colnames(temp_mat) <- make.unique(paste0(temp_coldata$biosample_ontology.term_name,":",temp_coldata$age_group)) --> -->
<!-- <!-- rownames(temp_mat) <- rownames(dataset_list$ENCODE_HH$median_norm_mat) --> -->

<!-- <!-- dot_sim <- similarity_func(temp_mat) --> -->
<!-- <!-- sim_tree <- cluster_func(dot_sim) --> -->
<!-- <!-- weights <- get_weights(sim_tree, colnames(temp_mat)) --> -->
<!-- <!-- weighted_means_2 <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.mean(x, weights=weights)}) --> -->
<!-- <!-- weighted_sds_2 <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.var(x, weights=weights)}) --> -->

<!-- <!-- df2 <- data.frame(biosample = temp_coldata$biosample_ontology.term_name, --> -->
<!-- <!--                  weights = weights) --> -->

<!-- <!-- ggplot(df2, aes(x=biosample))+ --> -->
<!-- <!--   geom_bar()+ --> -->
<!-- <!--   theme(axis.text.x  = element_text(angle = 90, vjust = 0.5, hjust=1)) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__endo_biosample_count.png")) --> -->

<!-- <!-- ggplot(df2, aes(x=biosample, y=weights))+ --> -->
<!-- <!--   geom_boxplot()+ --> -->
<!-- <!--   geom_point(aes(color=biosample),show.legend = F) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__endo_weights.png")) --> -->

<!-- <!-- aggregate(df2$weights, by=list(df2$biosample), FUN=sum) --> -->

<!-- <!-- temp_df <- aggregate(df2$weights, by=list(df2$biosample), FUN=sum)  --> -->
<!-- <!-- colnames(temp_df) <- c("biosample", "sum_of_weights") --> -->
<!-- <!-- ggplot(temp_df, aes(x=biosample, y=sum_of_weights))+ --> -->
<!-- <!--   geom_bar(stat="identity")+ --> -->
<!-- <!--   theme(axis.text.x  = element_text(angle = 90, vjust = 0.5, hjust=1)) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__endo_biosample_sum_of_weights.png")) --> -->


<!-- <!-- filename <- paste0(dirs$figures,"RD__endo_biosample_sim.png") --> -->
<!-- <!-- png(filename = filename, width=10,height=8,res=300,units = "in") --> -->
<!-- <!-- heatmap(dot_sim) --> -->
<!-- <!-- dev.off() --> -->

<!-- <!-- temp_mat <- dataset_list$ENCODE_HH$agg_med_norm__mat[,ehh_3] --> -->
<!-- <!-- temp_coldata <- dataset_list$ENCODE_HH$agg_med_norm__coldata[ehh_3,]  --> -->
<!-- <!-- colnames(temp_mat) <- make.unique(paste0(temp_coldata$biosample_ontology.term_name,":",temp_coldata$age_group)) --> -->
<!-- <!-- rownames(temp_mat) <- rownames(dataset_list$ENCODE_HH$median_norm_mat) --> -->

<!-- <!-- dot_sim <- similarity_func(temp_mat) --> -->
<!-- <!-- sim_tree <- cluster_func(dot_sim) --> -->
<!-- <!-- weights <- get_weights(sim_tree, colnames(temp_mat)) --> -->
<!-- <!-- weighted_means_3 <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.mean(x, weights=weights)}) --> -->
<!-- <!-- weighted_sds_3 <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.var(x, weights=weights)}) --> -->


<!-- <!-- df3 <- data.frame(biosample = temp_coldata$biosample_ontology.term_name, --> -->
<!-- <!--                  weights = weights) --> -->

<!-- <!-- ggplot(df3, aes(x=biosample))+ --> -->
<!-- <!--   geom_bar()+ --> -->
<!-- <!--   theme(axis.text.x  = element_text(angle = 90, vjust = 0.5, hjust=1)) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__ecto_biosample_count.png")) --> -->

<!-- <!-- ggplot(df3, aes(x=biosample, y=weights))+ --> -->
<!-- <!--   geom_boxplot()+ --> -->
<!-- <!--   geom_point(aes(color=biosample),show.legend = F) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__ecto_weights.png")) --> -->

<!-- <!-- aggregate(df3$weights, by=list(df3$biosample), FUN=sum) --> -->

<!-- <!-- temp_df <- aggregate(df3$weights, by=list(df3$biosample), FUN=sum)  --> -->
<!-- <!-- colnames(temp_df) <- c("biosample", "sum_of_weights") --> -->
<!-- <!-- ggplot(temp_df, aes(x=biosample, y=sum_of_weights))+ --> -->
<!-- <!--   geom_bar(stat="identity")+ --> -->
<!-- <!--   theme(axis.text.x  = element_text(angle = 90, vjust = 0.5, hjust=1)) --> -->
<!-- <!-- ggsave(filename = paste0(dirs$figures,"RD__ecto_biosample_sum_of_weights.png")) --> -->


<!-- <!-- filename <- paste0(dirs$figures,"RD__ecto_biosample_sim.png") --> -->
<!-- <!-- png(filename = filename, width=10,height=8,res=300,units = "in") --> -->
<!-- <!-- heatmap(dot_sim) --> -->
<!-- <!-- dev.off() --> -->


<!-- <!-- save.image("./post_wtd_onto_test.RData") --> -->
<!-- <!-- ``` --> -->

<!-- <!-- ```{r} --> -->

<!-- <!-- onto_name <- "mesoderm-derived structure" --> -->
<!-- <!-- onto_id <- onto$id[which(onto$name == onto_name)] --> -->
<!-- <!-- ehh_1 <- onto$ehh[[which(onto$id==onto_id)]] --> -->
<!-- <!-- onto_name <- "endoderm-derived structure" --> -->
<!-- <!-- onto_id <- onto$id[which(onto$name == onto_name)] --> -->
<!-- <!-- ehh_2 <- onto$ehh[[which(onto$id==onto_id)]] --> -->
<!-- <!-- onto_name <- "ectoderm-derived structure" --> -->
<!-- <!-- onto_id <- onto$id[which(onto$name == onto_name)] --> -->
<!-- <!-- ehh_3 <- onto$ehh[[which(onto$id==onto_id)]] --> -->
<!-- <!-- ### perform similarity reweighting --> -->


<!-- <!-- barplot(table(dataset_list$ENCODE_HH$coldata$biosample_ontology.term_name[ehh_1])) --> -->


<!-- <!-- ehh_2 --> -->
<!-- <!-- ehh_3 --> -->
<!-- <!-- ``` --> -->


<!-- <!-- ```{r} --> -->
<!-- <!-- plot(weighted_means_1, weighted_means_2) --> -->
<!-- <!-- plot(weighted_means_1, weighted_means_3) --> -->
<!-- <!-- plot(weighted_means_2, weighted_means_3) --> -->

<!-- <!-- df <- data.frame(meso=weighted_means_1,endo=weighted_means_2,ecto=weighted_means_3, --> -->
<!-- <!--                  meso_v=weighted_sds_1,endo_v=weighted_sds_2,ecto_v=weighted_sds_3) --> -->


<!-- <!-- ggplot(df, aes(x=meso, y=endo))+ --> -->
<!-- <!--   ggtitle("(ROUGH) Encode: tissues: meso-derived v endo-derived")+ --> -->
<!-- <!--   geom_point()+ --> -->
<!-- <!--   geom_abline(slope=1,intercept=0,color="red")+ --> -->
<!-- <!--   ylim(0,3)+xlim(0,3)+ --> -->
<!-- <!--   theme(text = element_text(size=16)) --> -->
<!-- <!-- filename <- paste0(dirs$figures, "RD__meso_v_endo.png") --> -->
<!-- <!-- ggsave(filename=filename, height = 6, width = 6, units="in" ) --> -->


<!-- <!-- ggplot(df, aes(x=meso, y=ecto))+ --> -->
<!-- <!--   ggtitle("(ROUGH) Encode: tissues: meso-derived v ecto-derived")+ --> -->
<!-- <!--   geom_point()+ --> -->
<!-- <!--   geom_abline(slope=1,intercept=0,color="red")+ --> -->
<!-- <!--   ylim(0,3)+xlim(0,3)+ --> -->
<!-- <!--   theme(text = element_text(size=16)) --> -->
<!-- <!-- filename <- paste0(dirs$figures, "RD__meso_v_ecto.png") --> -->
<!-- <!-- ggsave(filename=filename, height = 6, width = 6, units="in" ) --> -->


<!-- <!-- ggplot(df, aes(x=endo, y=ecto))+ --> -->
<!-- <!--   ggtitle("(ROUGH) Encode: tissues: endo-derived v ecto-derived")+ --> -->
<!-- <!--   geom_point()+ --> -->
<!-- <!--   geom_abline(slope=1,intercept=0,color="red")+ --> -->
<!-- <!--   ylim(0,3)+xlim(0,3)+ --> -->
<!-- <!--   theme(text = element_text(size=16)) --> -->
<!-- <!-- filename <- paste0(dirs$figures, "RD__endo_v_ecto.png") --> -->
<!-- <!-- ggsave(filename=filename, height = 6, width = 6, units="in" ) --> -->



<!-- <!-- ggl <- list() --> -->
<!-- <!-- ggl[["endo_ecto_meso"]] <- ggplot(df, aes(x=inheritance, fill=prob, y=prop))+ --> -->
<!-- <!--   geom_col(stat="identity", position=position_identity(), width = 0.99,)+ --> -->
<!-- <!--   scale_fill_manual(values=c("lightblue1","lightblue2","lightblue3","lightblue4","grey30","grey20"))+ --> -->
<!-- <!--   theme_classic()+ --> -->
<!-- <!--   theme(strip.text.y = element_text(angle = 0))+ --> -->
<!-- <!--   facet_grid(chrom_subset_name ~ .) --> -->


<!-- <!-- ``` --> -->



<!-- <!-- ### CHD ANALYSES --> -->

<!-- <!-- ```{r} --> -->


<!-- <!-- ``` --> -->


<!-- <!-- ```{r, muscle example r.e. ontologically organized analysis} --> -->

<!-- <!-- onto <- ontos$uberon$ont --> -->
<!-- <!-- mat <- dataset_list$ENCODE_HH$agg_med_norm__mat --> -->
<!-- <!-- coldata <- dataset_list$ENCODE_HH$agg_med_norm__coldata --> -->

<!-- <!-- #### ubiquitous, specific --> -->
<!-- <!-- #### all, mesoderm-derived, heart --> -->

<!-- <!-- temp_stat_df_model <- data.frame( --> -->
<!-- <!--   mean_internal = numeric(length=num_features), --> -->
<!-- <!--   sd_internal = numeric(length=num_features), --> -->
<!-- <!--   tau_internal = numeric(length=num_features), --> -->
<!-- <!--   mean_external = numeric(length=num_features), --> -->
<!-- <!--   sd_external = numeric(length=num_features), --> -->
<!-- <!--   tau_external = numeric(length=num_features) --> -->
<!-- <!-- ) --> -->
<!-- <!-- rownames(temp_stat_df_model) <- rownames(mat) --> -->

<!-- <!-- ## assumes p2 can contain p1 but not reverse --> -->
<!-- <!-- contrast_pairs <- list(list(name="left v right", --> -->
<!-- <!--                             p1="left cardiac chamber", --> -->
<!-- <!--                             p2="right cardiac chamber"), --> -->
<!-- <!--                        list(name="ventricle v atria", --> -->
<!-- <!--                             p1="cardiac ventricle", --> -->
<!-- <!--                             p2="cardiac atrium"), --> -->
<!-- <!--                        list(name="heart vasc v vasc", --> -->
<!-- <!--                             p1="heart blood vessel", --> -->
<!-- <!--                             p2="blood vessel"), --> -->
<!-- <!--                        list(name="great vessel v vasc", --> -->
<!-- <!--                             p1="great vessel of heart", --> -->
<!-- <!--                             p2="blood vasculature")) --> -->
<!-- <!--                        # list(name="striated muscle v all", --> -->
<!-- <!--                        #      p1="striated muscle tissue", --> -->
<!-- <!--                        #      p2="anatomical entity"), --> -->
<!-- <!--                        # list(name="cardiac muscle v all", --> -->
<!-- <!--                        #      p1="cardiac muscle tissue", --> -->
<!-- <!--                        #      p2="anatomical entity"), --> -->
<!-- <!--                        # list(name="skeletal muscle v all", --> -->
<!-- <!--                        #      p1="skeletal muscle tissue", --> -->
<!-- <!--                        #      p2="anatomical entity"), --> -->
<!-- <!--                        # list(name="smooth muscle v all", --> -->
<!-- <!--                        #      p1="smooth muscle tissue", --> -->
<!-- <!--                        #      p2="anatomical entity")) --> -->

<!-- <!-- for(i in 1:length(contrast_pairs)){ --> -->
<!-- <!--   temp_pair <- contrast_pairs[[i]] --> -->
<!-- <!--   print(temp_pair$name) --> -->

<!-- <!--   colset_list <- list( --> -->
<!-- <!--     ehh1 = onto$ehh[[which(onto$name==temp_pair$p1) ]], --> -->
<!-- <!--     ehh2 = setdiff(onto$ehh[[which(onto$name==temp_pair$p2)]] --> -->
<!-- <!--                    ,onto$ehh[[which(onto$name==temp_pair$p1)]]) --> -->
<!-- <!--   ) --> -->
<!-- <!--   temp_pair$summary_stats <- temp_stat_df_model --> -->
<!-- <!--   for(j in 1:length(colset_list)){ --> -->
<!-- <!--     ehh <- colset_list[[j]] --> -->
<!-- <!--     temp_mat <- mat[,ehh,drop=F] --> -->
<!-- <!--     temp_coldata <- coldata[ehh,,drop=F] --> -->
<!-- <!--     colnames(temp_mat) <- make.unique(paste0(temp_coldata$biosample_ontology.term_name, --> -->
<!-- <!--                                              ":",temp_coldata$age_group)) --> -->
<!-- <!--     dot_sim <- similarity_func(temp_mat) --> -->
<!-- <!--     rownames(dot_sim) <- colnames(dot_sim) <- colnames(temp_mat)  --> -->
<!-- <!--     sim_tree <- cluster_func(dot_sim) --> -->
<!-- <!--     weights <- get_weights(sim_tree, colnames(temp_mat)) --> -->
<!-- <!--     if(names(colset_list)[j]=="ehh1"){ --> -->
<!-- <!--       temp_pair$summary_stats$mean_internal <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.mean(x, weights=weights)}) --> -->
<!-- <!--       temp_pair$summary_stats$sd_internal <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.var(x, weights=weights)}) --> -->
<!-- <!--       temp_pair$summary_stats$tau_internal <- calc_weighted_tau(temp_mat,weights) --> -->
<!-- <!--     }else{ --> -->
<!-- <!--       temp_pair$summary_stats$mean_external <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.mean(x, weights=weights)}) --> -->
<!-- <!--       temp_pair$summary_stats$sd_external <- apply(temp_mat, MARGIN = 1, FUN = function(x){Hmisc::wtd.var(x, weights=weights)}) --> -->
<!-- <!--       temp_pair$summary_stats$tau_external <- calc_weighted_tau(temp_mat,weights) --> -->
<!-- <!--     } --> -->
<!-- <!--   } --> -->
<!-- <!--   contrast_pairs[[i]] <- temp_pair --> -->

<!-- <!-- } --> -->

<!-- <!-- for(i in 1:length(contrast_pairs)){ --> -->
<!-- <!--   contrast_pairs[[i]]$summary_stats$tau_delta <- contrast_pairs[[i]]$summary_stats$tau_external -  --> -->
<!-- <!--     contrast_pairs[[i]]$summary_stats$tau_internal --> -->
<!-- <!--   contrast_pairs[[i]]$summary_stats$mean_delta <- contrast_pairs[[i]]$summary_stats$mean_external -  --> -->
<!-- <!--     contrast_pairs[[i]]$summary_stats$mean_internal --> -->
<!-- <!-- } --> -->

<!-- <!-- save.image("post_contrast_heart.RData")  --> -->
<!-- <!-- ``` --> -->
